==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ConvolutionalNetwork                     [64, 2]                   --
├─Sequential: 1-1                        [64, 512, 7, 7]           3,911,808
│    └─Conv2d: 2-1                       [64, 64, 224, 224]        1,792
│    └─BatchNorm2d: 2-2                  [64, 64, 224, 224]        128
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-3                         [64, 64, 224, 224]        --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-4                    [64, 64, 112, 112]        --
│    └─Conv2d: 2-5                       [64, 128, 112, 112]       73,856
│    └─BatchNorm2d: 2-6                  [64, 128, 112, 112]       256
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-7                         [64, 128, 112, 112]       --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-8                    [64, 128, 56, 56]         --
│    └─Conv2d: 2-9                       [64, 256, 56, 56]         295,168
│    └─BatchNorm2d: 2-10                 [64, 256, 56, 56]         512
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-11                        [64, 256, 56, 56]         --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-12                   [64, 256, 28, 28]         --
│    └─Conv2d: 2-13                      [64, 512, 28, 28]         1,180,160
│    └─BatchNorm2d: 2-14                 [64, 512, 28, 28]         1,024
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-15                        [64, 512, 28, 28]         --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-16                   [64, 512, 14, 14]         --
│    └─Conv2d: 2-17                      [64, 512, 14, 14]         2,359,808
│    └─BatchNorm2d: 2-18                 [64, 512, 14, 14]         1,024
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-19                        [64, 512, 14, 14]         --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-20                   [64, 512, 7, 7]           --
├─Sequential: 1-12                       [64, 2]                   --
│    └─Linear: 2-21                      [64, 512]                 12,845,568
│    └─BatchNorm1d: 2-22                 [64, 512]                 1,024
│    └─ReLU: 2-23                        [64, 512]                 --
│    └─Dropout: 2-24                     [64, 512]                 --
│    └─Linear: 2-25                      [64, 256]                 131,328
│    └─BatchNorm1d: 2-26                 [64, 256]                 512
│    └─ReLU: 2-27                        [64, 256]                 --
│    └─Dropout: 2-28                     [64, 256]                 --
│    └─Linear: 2-29                      [64, 2]                   514
==========================================================================================
Total params: 20,804,482
Trainable params: 20,804,482
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 213.94
==========================================================================================
Input size (MB): 38.54
Forward/backward pass size (MB): 6269.17
Params size (MB): 67.57
Estimated Total Size (MB): 6375.28
==========================================================================================
Training and Validation Metrics:
Train Losses: [0.7047, 0.6393, 0.6206, 0.5876, 0.5801, 0.5693, 0.5562, 0.5508, 0.5197, 0.5229, 0.5215, 0.4906, 0.4835, 0.4614, 0.45, 0.4687, 0.4408, 0.4183, 0.4158, 0.3973, 0.3712, 0.4021, 0.3716, 0.3868, 0.3843, 0.3303, 0.3031, 0.2944, 0.3225, 0.3118, 0.2989, 0.2765, 0.2972, 0.2757, 0.2514, 0.286, 0.2438, 0.2286, 0.2383, 0.2089, 0.2168, 0.2216, 0.2208, 0.2285, 0.2159, 0.2089, 0.1955, 0.2087, 0.2035, 0.1823, 0.1732, 0.1742, 0.1615, 0.1429, 0.129, 0.1425, 0.1544, 0.1483, 0.1574, 0.1253, 0.167, 0.1581, 0.1563, 0.1228, 0.1254, 0.1189, 0.1289, 0.1008, 0.0984, 0.116, 0.1178, 0.1307, 0.1076, 0.1048, 0.1219, 0.0832, 0.0879, 0.1347, 0.0964, 0.095, 0.096, 0.0992, 0.0868, 0.0902, 0.0824, 0.0683, 0.0651, 0.0832, 0.0677, 0.0668, 0.0771, 0.0714, 0.0774, 0.0665, 0.0829, 0.0704, 0.0814, 0.0725, 0.0598, 0.0665, 0.0456, 0.0472, 0.0674, 0.0554, 0.0589, 0.0456, 0.0433, 0.0856, 0.0578, 0.0625, 0.0448, 0.0578, 0.0525, 0.051, 0.0532, 0.0564, 0.0544, 0.0606, 0.0563, 0.0384]
Train Accuracies: [55.85, 63.35, 66.35, 68.5, 69.85, 68.8, 72.05, 73.5, 73.9, 74.7, 75.45, 76.55, 77.25, 79.6, 79.4, 78.0, 79.45, 81.8, 81.9, 81.45, 83.45, 83.05, 83.2, 81.95, 82.6, 86.25, 86.35, 87.65, 85.8, 87.05, 86.45, 88.5, 87.1, 89.1, 90.2, 87.55, 89.35, 90.6, 90.1, 91.5, 91.05, 90.95, 90.6, 90.15, 90.85, 91.3, 92.1, 91.45, 91.45, 91.95, 93.45, 92.75, 93.55, 94.0, 94.85, 94.2, 93.95, 94.25, 93.95, 95.1, 94.75, 93.65, 93.85, 95.65, 95.05, 95.2, 95.0, 96.1, 96.2, 95.95, 95.65, 94.5, 95.65, 96.1, 95.7, 97.15, 96.85, 96.4, 96.5, 96.25, 96.45, 96.45, 97.05, 96.65, 96.75, 97.7, 97.65, 96.7, 97.15, 97.25, 97.55, 97.6, 97.05, 97.6, 96.95, 97.35, 96.75, 97.1, 97.7, 97.2, 98.5, 98.5, 97.7, 97.95, 98.0, 98.05, 98.3, 98.25, 97.95, 97.45, 98.6, 97.95, 98.15, 98.0, 97.95, 97.85, 98.0, 97.85, 97.65, 98.65]
Val Losses: [0.6922, 0.6482, 0.62, 0.698, 0.6019, 0.5931, 0.5676, 0.6502, 0.5756, 0.6711, 0.5439, 0.5044, 0.4873, 0.643, 0.6143, 0.5107, 0.5049, 0.4865, 0.4882, 0.5123, 0.4798, 0.5558, 0.4363, 0.7918, 0.4914, 0.3908, 0.462, 0.4229, 0.387, 0.3783, 0.3883, 0.3599, 0.3706, 0.3927, 0.3298, 0.3622, 0.358, 0.3856, 0.3534, 0.3663, 0.3586, 0.437, 0.3776, 0.3789, 0.4297, 0.3336, 0.5513, 0.3444, 0.4692, 0.3462, 0.3008, 0.3278, 0.3221, 0.3693, 0.4544, 0.3564, 0.3282, 0.3485, 0.307, 0.3293, 0.4046, 0.4881, 0.37, 0.3689, 0.346, 0.3387, 0.3249, 0.3334, 0.3412, 0.3617, 0.3561, 0.3677, 0.3262, 0.387, 0.4031, 0.3331, 0.3198, 0.3182, 0.3149, 0.3244, 0.3273, 0.3052, 0.3015, 0.2983, 0.306, 0.3179, 0.3229, 0.3387, 0.3406, 0.3052, 0.3154, 0.3325, 0.3195, 0.3369, 0.3272, 0.352, 0.3474, 0.3524, 0.3396, 0.3376, 0.35, 0.3313, 0.3263, 0.3132, 0.3411, 0.347, 0.3356, 0.3408, 0.3249, 0.3357, 0.34, 0.3215, 0.3348, 0.3671, 0.3569, 0.3501, 0.3818, 0.3494, 0.3548, 0.3839]
Val Accuracies: [62.0, 59.83, 64.17, 62.17, 66.17, 68.17, 69.17, 65.5, 72.0, 62.5, 74.5, 76.67, 75.83, 69.33, 72.0, 77.0, 75.5, 76.5, 78.5, 77.67, 78.33, 74.17, 81.33, 69.5, 79.17, 81.83, 81.67, 80.83, 83.83, 83.17, 84.67, 85.33, 84.83, 83.5, 86.0, 85.0, 85.5, 84.0, 85.33, 85.0, 84.17, 84.33, 85.5, 84.67, 86.5, 86.67, 81.5, 86.33, 85.33, 87.33, 89.0, 87.33, 88.0, 87.0, 86.17, 87.17, 88.33, 87.33, 89.5, 88.17, 87.5, 84.83, 87.5, 87.33, 88.83, 89.5, 91.0, 88.83, 89.5, 89.17, 88.67, 87.83, 88.83, 86.33, 86.17, 89.33, 89.5, 90.0, 89.5, 89.33, 89.67, 89.5, 89.0, 90.0, 90.0, 88.17, 89.17, 88.33, 89.17, 89.67, 89.83, 88.83, 89.17, 89.33, 89.33, 88.83, 90.0, 88.67, 89.5, 90.17, 89.0, 90.17, 90.17, 90.67, 90.67, 89.83, 89.67, 90.0, 89.5, 89.33, 89.5, 90.83, 90.5, 89.17, 89.33, 89.5, 89.67, 90.17, 89.33, 88.67]
