==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ConvolutionalNetwork                     [64, 2]                   --
├─Sequential: 1-1                        [64, 256, 14, 14]         388,416
│    └─Conv2d: 2-1                       [64, 32, 224, 224]        896
│    └─BatchNorm2d: 2-2                  [64, 32, 224, 224]        64
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-3                         [64, 32, 224, 224]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-4                    [64, 32, 112, 112]        --
│    └─Conv2d: 2-5                       [64, 64, 112, 112]        18,496
│    └─BatchNorm2d: 2-6                  [64, 64, 112, 112]        128
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-7                         [64, 64, 112, 112]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-8                    [64, 64, 56, 56]          --
│    └─Conv2d: 2-9                       [64, 128, 56, 56]         73,856
│    └─BatchNorm2d: 2-10                 [64, 128, 56, 56]         256
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-11                        [64, 128, 56, 56]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-12                   [64, 128, 28, 28]         --
│    └─Conv2d: 2-13                      [64, 256, 28, 28]         295,168
│    └─BatchNorm2d: 2-14                 [64, 256, 28, 28]         512
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-15                        [64, 256, 28, 28]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-16                   [64, 256, 14, 14]         --
├─Sequential: 1-10                       [64, 2]                   --
│    └─Linear: 2-17                      [64, 256]                 12,845,312
│    └─BatchNorm1d: 2-18                 [64, 256]                 512
│    └─ReLU: 2-19                        [64, 256]                 --
│    └─Dropout: 2-20                     [64, 256]                 --
│    └─Linear: 2-21                      [64, 128]                 32,896
│    └─BatchNorm1d: 2-22                 [64, 128]                 256
│    └─ReLU: 2-23                        [64, 128]                 --
│    └─Dropout: 2-24                     [64, 128]                 --
│    └─Linear: 2-25                      [64, 2]                   258
==========================================================================================
Total params: 13,657,026
Trainable params: 13,657,026
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 48.18
==========================================================================================
Input size (MB): 38.54
Forward/backward pass size (MB): 3083.21
Params size (MB): 53.07
Estimated Total Size (MB): 3174.82
==========================================================================================
Training and Validation Metrics:
Train Losses: [0.7296, 0.6625, 0.6499, 0.6114, 0.5968, 0.5875, 0.5664, 0.5664, 0.56, 0.5319, 0.5182, 0.5241, 0.5208, 0.5039, 0.5007, 0.4984, 0.4689, 0.4584, 0.4851, 0.4447, 0.4517, 0.4505, 0.4524, 0.4335, 0.4224, 0.4324, 0.425, 0.4183, 0.3865, 0.4187, 0.4107, 0.3893, 0.386, 0.3688, 0.3808, 0.3928, 0.3671, 0.3836, 0.3639, 0.3534, 0.3451, 0.3268, 0.3421, 0.3672, 0.3219, 0.3389, 0.3705, 0.3321, 0.3314, 0.3351, 0.3075, 0.3161, 0.2922, 0.3095, 0.3035, 0.3301, 0.302, 0.3084, 0.2859, 0.2924, 0.2776, 0.2766, 0.2761, 0.2712, 0.2862, 0.2473, 0.2396, 0.2589, 0.2636, 0.2828, 0.248, 0.2451, 0.2524, 0.2546, 0.2433, 0.2482, 0.2628, 0.2586, 0.2484, 0.2355, 0.2279, 0.2171, 0.2358, 0.2141, 0.2225, 0.2184, 0.2066, 0.2025, 0.2066, 0.1827, 0.1957, 0.2223, 0.2231, 0.2237, 0.1921, 0.2376, 0.1879, 0.1846, 0.1972, 0.1708]
Train Accuracies: [55.25, 59.65, 62.4, 66.25, 68.05, 69.4, 71.05, 70.55, 69.3, 72.5, 74.25, 73.45, 74.05, 75.3, 75.05, 76.25, 78.15, 78.35, 77.4, 79.65, 78.85, 79.65, 78.55, 80.45, 79.75, 81.05, 81.2, 80.9, 83.0, 79.9, 81.2, 82.7, 83.45, 83.5, 83.05, 82.35, 83.95, 83.9, 84.2, 84.4, 84.05, 85.2, 85.05, 83.25, 86.5, 85.85, 84.0, 86.55, 85.9, 85.0, 86.35, 85.85, 87.05, 86.2, 87.6, 86.2, 86.45, 85.8, 87.95, 86.75, 88.35, 88.15, 89.05, 88.1, 87.9, 90.15, 89.75, 88.75, 88.85, 86.85, 90.0, 90.25, 89.1, 89.6, 89.15, 89.0, 88.95, 88.6, 90.0, 90.85, 90.35, 90.65, 90.05, 91.25, 90.7, 91.15, 92.0, 91.35, 91.7, 93.1, 92.1, 90.65, 92.2, 91.0, 93.75, 90.3, 93.0, 92.35, 91.25, 93.4]
Val Losses: [0.6758, 0.6509, 0.6896, 0.6135, 0.6197, 0.6009, 0.5963, 0.5943, 0.5686, 0.5699, 0.5902, 0.5457, 0.5457, 0.6632, 0.5295, 0.5172, 0.5467, 0.5524, 0.5033, 0.4869, 0.4909, 0.5564, 0.478, 0.4891, 0.4713, 0.6155, 0.4747, 0.4519, 0.4816, 0.4631, 0.5306, 0.5552, 0.4886, 0.461, 0.5485, 0.5944, 0.5215, 0.4598, 0.6284, 0.4412, 0.4749, 0.4161, 0.4602, 0.4292, 0.4515, 0.4224, 0.5, 0.4028, 0.4517, 0.5696, 0.3963, 0.4248, 0.4027, 0.4088, 0.4394, 0.4453, 0.476, 0.4799, 0.43, 0.4641, 0.4242, 0.443, 0.4354, 0.3878, 0.3849, 0.3677, 0.4966, 0.3993, 0.4466, 0.3755, 0.4505, 0.4188, 0.3787, 0.4335, 0.3956, 0.5032, 0.3951, 0.4993, 0.4067, 0.4178, 0.4898, 0.3955, 0.3982, 0.3942, 0.4628, 0.5227, 0.3878, 0.3946, 0.4621, 0.389, 0.4204, 0.4107, 0.3389, 0.4073, 0.4446, 0.3971, 0.5073, 0.4436, 0.3673, 0.5312]
Val Accuracies: [57.5, 64.5, 63.17, 66.83, 62.67, 68.33, 71.0, 69.5, 68.0, 69.5, 69.5, 73.5, 71.83, 67.0, 73.5, 74.83, 73.33, 74.83, 76.17, 76.5, 76.17, 74.17, 77.17, 76.83, 77.83, 72.33, 77.67, 78.83, 76.5, 76.33, 75.17, 73.5, 77.17, 78.33, 77.67, 75.83, 74.0, 79.0, 71.67, 78.67, 79.33, 81.33, 77.83, 81.33, 81.17, 82.67, 73.83, 81.83, 80.83, 75.5, 83.17, 84.33, 83.83, 83.5, 80.83, 82.83, 79.17, 81.5, 81.67, 82.0, 82.33, 82.0, 82.83, 83.5, 84.83, 84.5, 81.33, 83.83, 82.5, 84.83, 82.5, 84.0, 85.5, 83.83, 85.0, 82.5, 84.33, 82.0, 84.17, 84.83, 83.0, 84.5, 83.33, 86.17, 83.83, 81.5, 87.17, 85.33, 82.67, 85.0, 83.83, 84.67, 87.0, 85.0, 83.5, 85.33, 81.83, 82.5, 85.67, 83.67]
