==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ConvolutionalNetwork                     [64, 2]                   --
├─Sequential: 1-1                        [64, 256, 14, 14]         388,416
│    └─Conv2d: 2-1                       [64, 32, 224, 224]        896
│    └─BatchNorm2d: 2-2                  [64, 32, 224, 224]        64
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-3                         [64, 32, 224, 224]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-4                    [64, 32, 112, 112]        --
│    └─Conv2d: 2-5                       [64, 64, 112, 112]        18,496
│    └─BatchNorm2d: 2-6                  [64, 64, 112, 112]        128
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-7                         [64, 64, 112, 112]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-8                    [64, 64, 56, 56]          --
│    └─Conv2d: 2-9                       [64, 128, 56, 56]         73,856
│    └─BatchNorm2d: 2-10                 [64, 128, 56, 56]         256
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-11                        [64, 128, 56, 56]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-12                   [64, 128, 28, 28]         --
│    └─Conv2d: 2-13                      [64, 256, 28, 28]         295,168
│    └─BatchNorm2d: 2-14                 [64, 256, 28, 28]         512
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-15                        [64, 256, 28, 28]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-16                   [64, 256, 14, 14]         --
├─Sequential: 1-10                       [64, 2]                   --
│    └─Linear: 2-17                      [64, 256]                 12,845,312
│    └─BatchNorm1d: 2-18                 [64, 256]                 512
│    └─ReLU: 2-19                        [64, 256]                 --
│    └─Dropout: 2-20                     [64, 256]                 --
│    └─Linear: 2-21                      [64, 128]                 32,896
│    └─BatchNorm1d: 2-22                 [64, 128]                 256
│    └─ReLU: 2-23                        [64, 128]                 --
│    └─Dropout: 2-24                     [64, 128]                 --
│    └─Linear: 2-25                      [64, 2]                   258
==========================================================================================
Total params: 13,657,026
Trainable params: 13,657,026
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 48.18
==========================================================================================
Input size (MB): 38.54
Forward/backward pass size (MB): 3083.21
Params size (MB): 53.07
Estimated Total Size (MB): 3174.82
==========================================================================================
Training and Validation Metrics:
Train Losses: [0.729, 0.6922, 0.6484, 0.6328, 0.5978, 0.5903, 0.5706, 0.5907, 0.5632, 0.5417, 0.5323, 0.5348, 0.4983, 0.5085, 0.4916, 0.4772, 0.4724, 0.4934, 0.467, 0.4634, 0.4569, 0.4314, 0.4312, 0.423, 0.4545, 0.4099, 0.3944, 0.3976, 0.3868, 0.3653, 0.3532, 0.3456, 0.3783, 0.3705, 0.3691, 0.3505, 0.3457, 0.3255, 0.345, 0.3262, 0.3433, 0.3577, 0.332, 0.3165, 0.3151, 0.3056, 0.3292, 0.3056, 0.3322, 0.3435, 0.2875, 0.2779, 0.2883, 0.2725, 0.2767, 0.2719, 0.2617, 0.255, 0.2464, 0.2497, 0.2424, 0.2534, 0.2904, 0.247, 0.2441, 0.2496, 0.2242, 0.2458, 0.2558, 0.2568, 0.2368, 0.2242, 0.2738, 0.2375, 0.2252, 0.2277, 0.2028, 0.1926, 0.1814, 0.2095, 0.2108, 0.1966, 0.1815, 0.1857, 0.1977, 0.1902, 0.1822, 0.1666, 0.2, 0.1859, 0.1751, 0.1714, 0.164, 0.1783, 0.175, 0.1994, 0.168, 0.1767, 0.1624, 0.1739]
Train Accuracies: [55.65, 59.3, 63.3, 65.6, 69.2, 67.35, 71.15, 68.1, 71.0, 72.4, 73.05, 73.7, 76.3, 75.05, 75.85, 77.1, 77.15, 76.5, 78.3, 78.3, 79.2, 80.1, 79.55, 81.55, 79.65, 80.15, 82.8, 82.25, 83.35, 83.0, 84.95, 84.5, 82.9, 83.8, 83.65, 83.8, 84.4, 85.6, 84.4, 86.45, 85.4, 84.15, 86.25, 86.45, 85.5, 86.0, 85.8, 86.9, 85.55, 85.0, 87.85, 87.6, 87.05, 89.05, 88.7, 88.5, 88.7, 89.65, 89.6, 88.95, 90.5, 88.8, 88.55, 89.4, 90.1, 89.95, 90.95, 90.1, 89.6, 88.1, 90.05, 90.5, 89.45, 90.0, 90.35, 89.95, 92.15, 91.85, 92.4, 91.35, 91.55, 92.2, 92.75, 92.8, 91.9, 92.35, 92.3, 93.15, 92.3, 92.5, 93.0, 93.1, 93.9, 92.2, 93.15, 92.3, 93.55, 93.3, 93.25, 92.8]
Val Losses: [0.6818, 0.6318, 0.631, 0.628, 0.6195, 0.5944, 0.615, 0.6335, 0.5735, 0.5821, 0.5519, 0.5723, 0.5843, 0.5794, 0.5195, 0.5717, 0.5965, 0.5095, 0.4942, 0.5228, 0.5311, 0.608, 0.4788, 0.4979, 0.6975, 0.4999, 0.4594, 0.4734, 0.4792, 0.4939, 0.4752, 0.4913, 0.4302, 0.5041, 0.5149, 0.4423, 0.484, 0.5094, 0.4696, 0.4302, 0.4846, 0.4671, 0.5145, 0.4251, 0.4495, 0.4387, 0.4326, 0.4349, 0.4634, 0.451, 0.3979, 0.4462, 0.4167, 0.4036, 0.4041, 0.3961, 0.4255, 0.4006, 0.4057, 0.3919, 0.4371, 0.4562, 0.4465, 0.4374, 0.4193, 0.4722, 0.4265, 0.4239, 0.4182, 0.398, 0.4024, 0.4306, 0.3933, 0.4002, 0.3919, 0.4214, 0.4027, 0.3897, 0.3962, 0.3954, 0.3921, 0.399, 0.4037, 0.4145, 0.4357, 0.4049, 0.4516, 0.418, 0.4241, 0.4002, 0.4566, 0.413, 0.3991, 0.4344, 0.4216, 0.4407, 0.4359, 0.4228, 0.413, 0.4174]
Val Accuracies: [56.67, 64.33, 65.0, 67.83, 66.17, 67.67, 66.67, 65.33, 71.0, 70.33, 71.33, 70.5, 70.67, 71.5, 75.83, 72.33, 71.0, 75.33, 76.83, 74.5, 74.33, 75.0, 77.17, 77.17, 67.5, 76.67, 78.5, 79.83, 79.0, 76.5, 78.17, 76.33, 82.0, 77.17, 73.5, 80.33, 78.33, 79.33, 81.33, 80.67, 79.17, 81.33, 77.67, 81.17, 81.33, 81.83, 82.67, 82.83, 80.83, 81.33, 83.17, 80.5, 81.17, 84.17, 83.33, 84.5, 83.83, 83.0, 83.83, 84.5, 82.5, 84.17, 82.33, 83.33, 84.0, 82.0, 81.83, 84.83, 83.67, 84.0, 82.67, 83.17, 85.33, 84.5, 84.67, 83.67, 83.83, 86.17, 86.0, 85.33, 84.5, 85.83, 85.17, 84.0, 84.0, 85.17, 83.33, 85.0, 84.0, 85.0, 85.33, 84.5, 84.83, 84.5, 85.67, 84.5, 85.33, 85.0, 84.83, 85.67]
