==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ConvolutionalNetwork                     [64, 2]                   --
├─Sequential: 1-1                        [64, 512, 7, 7]           3,911,808
│    └─Conv2d: 2-1                       [64, 64, 224, 224]        1,792
│    └─BatchNorm2d: 2-2                  [64, 64, 224, 224]        128
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-3                         [64, 64, 224, 224]        --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-4                    [64, 64, 112, 112]        --
│    └─Conv2d: 2-5                       [64, 128, 112, 112]       73,856
│    └─BatchNorm2d: 2-6                  [64, 128, 112, 112]       256
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-7                         [64, 128, 112, 112]       --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-8                    [64, 128, 56, 56]         --
│    └─Conv2d: 2-9                       [64, 256, 56, 56]         295,168
│    └─BatchNorm2d: 2-10                 [64, 256, 56, 56]         512
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-11                        [64, 256, 56, 56]         --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-12                   [64, 256, 28, 28]         --
│    └─Conv2d: 2-13                      [64, 512, 28, 28]         1,180,160
│    └─BatchNorm2d: 2-14                 [64, 512, 28, 28]         1,024
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-15                        [64, 512, 28, 28]         --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-16                   [64, 512, 14, 14]         --
│    └─Conv2d: 2-17                      [64, 512, 14, 14]         2,359,808
│    └─BatchNorm2d: 2-18                 [64, 512, 14, 14]         1,024
├─Sequential: 1-10                       --                        (recursive)
│    └─ReLU: 2-19                        [64, 512, 14, 14]         --
├─Sequential: 1-11                       --                        (recursive)
│    └─MaxPool2d: 2-20                   [64, 512, 7, 7]           --
├─Sequential: 1-12                       [64, 2]                   --
│    └─Linear: 2-21                      [64, 512]                 12,845,568
│    └─BatchNorm1d: 2-22                 [64, 512]                 1,024
│    └─ReLU: 2-23                        [64, 512]                 --
│    └─Dropout: 2-24                     [64, 512]                 --
│    └─Linear: 2-25                      [64, 256]                 131,328
│    └─BatchNorm1d: 2-26                 [64, 256]                 512
│    └─ReLU: 2-27                        [64, 256]                 --
│    └─Dropout: 2-28                     [64, 256]                 --
│    └─Linear: 2-29                      [64, 2]                   514
==========================================================================================
Total params: 20,804,482
Trainable params: 20,804,482
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 213.94
==========================================================================================
Input size (MB): 38.54
Forward/backward pass size (MB): 6269.17
Params size (MB): 67.57
Estimated Total Size (MB): 6375.28
==========================================================================================
Training and Validation Metrics:
Train Losses: [0.7206, 0.6802, 0.6636, 0.6367, 0.6149, 0.6022, 0.5728, 0.5657, 0.5561, 0.5503, 0.5269, 0.5106, 0.5094, 0.499, 0.4923, 0.4936, 0.4631, 0.4567, 0.4417, 0.4621, 0.4443, 0.4118, 0.4778, 0.4142, 0.4148, 0.4125, 0.3962, 0.3772, 0.3432, 0.3646, 0.3487, 0.3363, 0.3626, 0.3289, 0.3029, 0.3089, 0.3221, 0.2892, 0.2993, 0.3062, 0.2927, 0.2845, 0.2866, 0.2843, 0.2659, 0.2761, 0.2852, 0.2639, 0.2497, 0.26, 0.2528, 0.2187, 0.2296, 0.2347, 0.2162, 0.194, 0.1849, 0.2236, 0.1955, 0.2079, 0.2027, 0.2129, 0.1757, 0.1723, 0.1906, 0.1713, 0.1631, 0.1673, 0.1557, 0.1711, 0.1537, 0.1642, 0.1374, 0.1266, 0.1609, 0.1678, 0.1437, 0.1824, 0.1366, 0.1377, 0.1326, 0.1139, 0.152, 0.1272, 0.1166, 0.1233, 0.1655, 0.1296, 0.1159, 0.1388, 0.1342, 0.1434, 0.124, 0.0916, 0.0975, 0.1017, 0.1237, 0.1012, 0.1016, 0.099, 0.1105, 0.1064, 0.1173, 0.1039, 0.1126, 0.108, 0.0932, 0.0998, 0.1282, 0.0889, 0.0856, 0.0883, 0.09, 0.076, 0.0827, 0.1015, 0.0798, 0.0842, 0.0669, 0.074]
Train Accuracies: [55.15, 57.9, 60.65, 63.45, 66.1, 66.6, 70.7, 71.15, 71.15, 72.65, 72.9, 74.65, 75.35, 75.45, 76.7, 76.9, 79.3, 78.95, 78.95, 78.85, 79.3, 80.95, 76.4, 80.8, 80.4, 81.5, 81.2, 84.1, 84.6, 83.65, 84.25, 84.75, 83.65, 85.75, 87.25, 86.5, 86.55, 87.15, 87.1, 86.55, 87.4, 87.9, 88.35, 88.35, 89.25, 88.7, 87.85, 88.0, 89.95, 89.6, 89.4, 90.6, 90.75, 90.05, 90.7, 92.0, 92.7, 90.8, 91.55, 91.6, 91.7, 90.4, 92.8, 92.95, 92.45, 92.95, 93.3, 93.75, 93.7, 93.1, 93.9, 93.2, 94.15, 95.05, 93.7, 92.65, 94.8, 92.7, 94.65, 94.35, 95.3, 95.55, 93.85, 95.35, 95.5, 95.45, 94.05, 94.65, 95.75, 94.2, 94.9, 94.15, 95.05, 96.35, 96.0, 96.3, 94.3, 95.9, 96.25, 95.95, 95.7, 96.0, 95.05, 95.8, 96.5, 96.3, 96.2, 96.5, 95.3, 96.6, 96.65, 96.85, 96.55, 97.1, 96.75, 96.25, 96.95, 96.95, 97.25, 97.15]
Val Losses: [0.7543, 0.7889, 0.6234, 0.5956, 0.6728, 0.6197, 0.596, 0.7474, 0.5889, 0.5609, 0.5995, 0.5758, 0.5395, 0.547, 0.6012, 0.499, 0.5559, 0.5044, 0.5147, 0.4939, 0.5131, 0.6186, 0.4806, 0.4869, 0.4357, 0.4279, 0.4663, 0.4881, 0.4451, 0.4301, 0.5731, 0.5071, 0.3897, 0.3771, 0.4087, 0.3707, 0.4977, 0.3727, 0.4675, 0.3523, 0.3551, 0.3976, 0.6133, 0.3339, 0.3488, 0.3933, 0.3365, 0.3755, 0.7493, 0.2911, 0.3326, 0.4604, 0.3377, 0.4674, 0.3766, 0.3656, 0.3781, 0.7648, 0.4405, 0.352, 0.3833, 0.3591, 0.3098, 0.312, 0.3507, 0.331, 0.2971, 0.3352, 0.4033, 0.308, 0.3449, 0.3177, 0.2684, 0.2855, 0.3289, 0.2932, 0.4449, 0.3284, 0.317, 0.3692, 0.2757, 0.3848, 0.3718, 0.3369, 0.2958, 0.3126, 0.3738, 0.2697, 0.5481, 0.4467, 0.2801, 0.3517, 0.2855, 0.3218, 0.5325, 0.3723, 0.2634, 0.3041, 0.3535, 0.2743, 0.2681, 0.466, 0.2934, 0.2386, 0.3063, 0.335, 0.2827, 0.317, 0.302, 0.4448, 0.2558, 0.2908, 0.2865, 0.275, 0.2618, 0.2775, 0.3634, 0.2854, 0.249, 0.3117]
Val Accuracies: [56.83, 58.5, 63.0, 68.83, 61.5, 65.0, 68.67, 61.0, 70.33, 71.17, 64.33, 72.5, 74.83, 74.0, 68.67, 74.83, 72.17, 73.5, 75.83, 78.17, 75.17, 73.5, 78.0, 77.17, 78.0, 81.17, 79.33, 78.5, 81.0, 81.17, 76.0, 76.17, 82.5, 86.0, 84.0, 84.0, 80.0, 85.17, 81.17, 84.83, 83.83, 83.5, 78.5, 85.5, 84.67, 86.33, 84.83, 84.0, 73.17, 88.33, 86.0, 82.83, 86.0, 82.5, 85.0, 86.33, 85.67, 75.83, 84.0, 87.0, 86.17, 86.0, 88.33, 87.5, 86.83, 87.17, 89.0, 88.67, 87.17, 89.67, 86.83, 88.0, 88.83, 88.83, 89.33, 88.17, 85.17, 87.0, 87.33, 87.5, 87.67, 87.17, 86.0, 87.0, 89.67, 88.5, 87.67, 90.0, 85.0, 87.17, 90.83, 88.5, 89.83, 90.33, 85.17, 88.0, 91.0, 90.33, 88.33, 91.17, 90.33, 88.0, 89.83, 91.5, 90.83, 89.67, 90.33, 89.67, 89.5, 85.83, 90.0, 90.17, 90.67, 91.33, 92.17, 90.33, 88.17, 90.67, 91.83, 91.67]
