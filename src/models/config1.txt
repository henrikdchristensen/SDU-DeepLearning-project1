==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ConvolutionalNetwork                     [64, 2]                   --
├─Sequential: 1-1                        [64, 256, 14, 14]         388,416
│    └─Conv2d: 2-1                       [64, 32, 224, 224]        896
│    └─BatchNorm2d: 2-2                  [64, 32, 224, 224]        64
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-3                         [64, 32, 224, 224]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-4                    [64, 32, 112, 112]        --
│    └─Conv2d: 2-5                       [64, 64, 112, 112]        18,496
│    └─BatchNorm2d: 2-6                  [64, 64, 112, 112]        128
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-7                         [64, 64, 112, 112]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-8                    [64, 64, 56, 56]          --
│    └─Conv2d: 2-9                       [64, 128, 56, 56]         73,856
│    └─BatchNorm2d: 2-10                 [64, 128, 56, 56]         256
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-11                        [64, 128, 56, 56]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-12                   [64, 128, 28, 28]         --
│    └─Conv2d: 2-13                      [64, 256, 28, 28]         295,168
│    └─BatchNorm2d: 2-14                 [64, 256, 28, 28]         512
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-15                        [64, 256, 28, 28]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-16                   [64, 256, 14, 14]         --
├─Sequential: 1-10                       [64, 2]                   --
│    └─Linear: 2-17                      [64, 256]                 12,845,312
│    └─BatchNorm1d: 2-18                 [64, 256]                 512
│    └─ReLU: 2-19                        [64, 256]                 --
│    └─Dropout: 2-20                     [64, 256]                 --
│    └─Linear: 2-21                      [64, 128]                 32,896
│    └─BatchNorm1d: 2-22                 [64, 128]                 256
│    └─ReLU: 2-23                        [64, 128]                 --
│    └─Dropout: 2-24                     [64, 128]                 --
│    └─Linear: 2-25                      [64, 2]                   258
==========================================================================================
Total params: 13,657,026
Trainable params: 13,657,026
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 48.18
==========================================================================================
Input size (MB): 38.54
Forward/backward pass size (MB): 3083.21
Params size (MB): 53.07
Estimated Total Size (MB): 3174.82
==========================================================================================
Training and Validation Metrics:
Train Losses: [0.7307, 0.6521, 0.6375, 0.5927, 0.5778, 0.5984, 0.5715, 0.5698, 0.544, 0.5543, 0.545, 0.5269, 0.5243, 0.5198, 0.5079, 0.491, 0.5052, 0.4668, 0.4764, 0.4647, 0.4696, 0.4272, 0.458, 0.4482, 0.4422, 0.4215, 0.407, 0.4149, 0.4057, 0.4144, 0.3979, 0.3875, 0.4139, 0.3845, 0.3752, 0.3977, 0.3625, 0.3645, 0.3627, 0.3747, 0.3699, 0.3573, 0.3574, 0.3369, 0.3604, 0.3408, 0.3239, 0.3166, 0.3203, 0.3443, 0.3251, 0.3025, 0.3013, 0.3074, 0.297, 0.3085, 0.3069, 0.286, 0.2871, 0.2852, 0.2751, 0.285, 0.3086, 0.2725, 0.2711, 0.2683, 0.2684, 0.2513, 0.2631, 0.2776, 0.2483, 0.2647, 0.243, 0.2503, 0.2707, 0.2457, 0.2471, 0.245, 0.2515, 0.2297, 0.2263, 0.2443, 0.2364, 0.222, 0.2211, 0.198, 0.2174, 0.2209, 0.2192, 0.2318, 0.2028, 0.2053, 0.2, 0.228, 0.1917, 0.211, 0.2143, 0.2099, 0.1857, 0.1776]
Train Accuracies: [56.0, 62.95, 63.75, 68.1, 69.7, 67.25, 69.45, 70.25, 73.35, 71.25, 72.45, 74.2, 73.5, 75.05, 74.65, 76.1, 75.95, 78.3, 78.25, 77.25, 77.55, 80.45, 78.8, 78.5, 80.35, 81.65, 81.2, 80.9, 82.0, 80.7, 80.8, 82.5, 81.4, 82.35, 83.4, 82.95, 83.45, 83.8, 83.25, 83.0, 83.5, 84.45, 84.75, 85.95, 84.4, 84.65, 85.8, 85.3, 85.05, 86.1, 85.75, 87.2, 87.45, 87.0, 87.15, 86.05, 86.55, 87.9, 88.4, 88.5, 88.3, 87.45, 86.85, 88.05, 88.45, 88.3, 89.05, 89.9, 88.75, 88.85, 89.2, 89.15, 89.85, 89.15, 88.75, 90.05, 89.25, 88.95, 88.8, 90.3, 91.0, 89.55, 89.75, 91.05, 90.95, 91.7, 91.35, 90.95, 91.3, 90.35, 92.25, 91.9, 91.6, 90.7, 91.9, 91.2, 91.6, 91.45, 92.1, 93.15]
Val Losses: [0.6465, 0.6604, 0.6547, 0.6231, 0.6625, 0.6261, 0.5945, 0.5812, 0.6351, 0.6418, 0.6421, 0.6598, 0.5408, 0.5884, 0.5348, 0.7672, 0.5747, 0.5298, 0.5794, 0.5572, 0.5894, 0.5688, 0.5592, 0.5245, 0.4817, 0.8013, 0.4993, 0.5497, 0.5137, 0.4932, 0.5299, 0.5282, 0.5049, 0.5308, 0.6375, 0.4545, 0.4376, 0.4203, 0.4495, 0.4405, 0.4415, 0.4113, 0.4531, 0.4608, 0.4689, 0.472, 0.4159, 0.4413, 0.5258, 0.4423, 0.3925, 0.4084, 0.4423, 0.4522, 0.4172, 0.4486, 0.4188, 0.4898, 0.4291, 0.4121, 0.4387, 0.5501, 0.4401, 0.4686, 0.421, 0.4653, 0.6943, 0.4086, 0.4757, 0.5914, 0.4847, 0.3794, 0.3707, 0.5753, 0.3772, 0.4399, 0.4045, 0.7309, 0.4149, 0.4104, 0.3988, 0.3981, 0.3351, 0.3877, 0.3517, 0.4356, 0.3679, 0.4307, 0.4436, 0.4275, 0.3612, 0.3982, 0.4003, 0.4731, 0.3789, 0.4272, 0.5548, 0.3959, 0.4187, 0.3972]
Val Accuracies: [59.67, 64.67, 63.33, 65.83, 64.67, 66.0, 68.5, 69.5, 67.83, 66.5, 68.33, 66.5, 72.5, 71.17, 72.83, 63.67, 72.67, 74.83, 73.5, 71.33, 72.0, 74.17, 75.17, 77.0, 77.17, 64.67, 76.67, 77.5, 78.17, 77.83, 76.67, 76.17, 76.83, 76.17, 74.5, 80.33, 81.0, 80.83, 80.0, 80.5, 81.33, 81.83, 80.5, 79.5, 80.17, 79.17, 82.17, 80.83, 79.0, 80.17, 83.17, 82.5, 83.0, 82.17, 82.67, 81.0, 83.0, 82.33, 83.0, 83.83, 81.5, 79.17, 82.17, 82.33, 82.17, 84.0, 75.5, 83.67, 82.17, 76.5, 81.17, 85.17, 86.17, 79.0, 84.67, 83.67, 84.33, 78.33, 83.67, 84.67, 85.0, 85.67, 87.33, 83.5, 85.17, 84.83, 86.5, 84.5, 84.67, 84.67, 86.5, 86.17, 85.67, 84.33, 87.5, 85.5, 83.17, 85.67, 85.5, 86.5]
