==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ConvolutionalNetwork                     [64, 2]                   --
├─Sequential: 1-1                        [64, 256, 14, 14]         388,416
│    └─Conv2d: 2-1                       [64, 32, 224, 224]        896
│    └─BatchNorm2d: 2-2                  [64, 32, 224, 224]        64
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-3                         [64, 32, 224, 224]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-4                    [64, 32, 112, 112]        --
│    └─Conv2d: 2-5                       [64, 64, 112, 112]        18,496
│    └─BatchNorm2d: 2-6                  [64, 64, 112, 112]        128
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-7                         [64, 64, 112, 112]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-8                    [64, 64, 56, 56]          --
│    └─Conv2d: 2-9                       [64, 128, 56, 56]         73,856
│    └─BatchNorm2d: 2-10                 [64, 128, 56, 56]         256
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-11                        [64, 128, 56, 56]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-12                   [64, 128, 28, 28]         --
│    └─Conv2d: 2-13                      [64, 256, 28, 28]         295,168
│    └─BatchNorm2d: 2-14                 [64, 256, 28, 28]         512
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-15                        [64, 256, 28, 28]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-16                   [64, 256, 14, 14]         --
├─Sequential: 1-10                       [64, 2]                   --
│    └─Linear: 2-17                      [64, 256]                 12,845,312
│    └─BatchNorm1d: 2-18                 [64, 256]                 512
│    └─ReLU: 2-19                        [64, 256]                 --
│    └─Dropout: 2-20                     [64, 256]                 --
│    └─Linear: 2-21                      [64, 128]                 32,896
│    └─BatchNorm1d: 2-22                 [64, 128]                 256
│    └─ReLU: 2-23                        [64, 128]                 --
│    └─Dropout: 2-24                     [64, 128]                 --
│    └─Linear: 2-25                      [64, 2]                   258
==========================================================================================
Total params: 13,657,026
Trainable params: 13,657,026
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 48.18
==========================================================================================
Input size (MB): 38.54
Forward/backward pass size (MB): 3083.21
Params size (MB): 53.07
Estimated Total Size (MB): 3174.82
==========================================================================================
Training and Validation Metrics:
Train Losses: [0.7298, 0.6562, 0.6341, 0.5988, 0.5869, 0.5986, 0.5675, 0.5779, 0.5537, 0.5627, 0.5404, 0.5449, 0.5454, 0.5339, 0.5159, 0.4974, 0.5281, 0.4898, 0.4898, 0.4705, 0.4794, 0.4373, 0.4741, 0.4476, 0.4423, 0.4215, 0.4054, 0.4256, 0.3957, 0.4313, 0.4195, 0.389, 0.4085, 0.3853, 0.379, 0.3882, 0.3691, 0.357, 0.3516, 0.3769, 0.3667, 0.3519, 0.3606, 0.3464, 0.3582, 0.3416, 0.3191, 0.313, 0.3333, 0.3237, 0.3371, 0.297, 0.2877, 0.3102, 0.2925, 0.2878, 0.297, 0.2914, 0.2874, 0.2685, 0.2804, 0.2813, 0.3013, 0.2765, 0.2714, 0.2629, 0.2664, 0.2428, 0.2507, 0.2644, 0.2607, 0.2567, 0.2442, 0.2259, 0.2456, 0.2452, 0.2571, 0.2338, 0.2348, 0.2238, 0.2211, 0.2453, 0.2396, 0.2135, 0.2122, 0.2036, 0.2174, 0.2114, 0.2068, 0.21, 0.2005, 0.22, 0.1953, 0.2081, 0.2116, 0.2036, 0.1804, 0.2084, 0.1799, 0.1578]
Train Accuracies: [55.5, 62.95, 64.45, 66.75, 69.45, 67.35, 70.0, 69.4, 72.9, 70.4, 71.75, 73.75, 71.5, 74.6, 74.8, 76.05, 75.0, 76.6, 76.8, 76.8, 76.6, 79.25, 76.9, 78.9, 79.75, 80.85, 80.6, 80.6, 83.2, 80.05, 80.35, 82.95, 80.95, 82.8, 83.5, 83.2, 83.55, 84.85, 83.6, 83.4, 84.5, 85.8, 84.25, 85.3, 83.9, 85.4, 86.0, 86.25, 84.4, 86.95, 85.8, 87.55, 87.95, 87.2, 87.4, 87.7, 87.05, 86.2, 88.4, 89.45, 88.2, 87.95, 86.75, 87.25, 88.75, 88.4, 88.5, 90.2, 90.05, 89.45, 89.05, 88.65, 88.9, 90.45, 89.95, 89.55, 88.6, 89.75, 89.85, 90.8, 90.45, 89.7, 89.4, 91.05, 91.4, 91.6, 91.4, 90.75, 91.5, 91.55, 92.3, 91.85, 92.4, 91.95, 91.1, 92.4, 92.85, 91.4, 92.75, 93.85]
Val Losses: [0.6586, 0.6454, 0.6294, 0.6188, 0.6422, 0.6206, 0.5932, 0.6027, 0.5887, 0.6505, 0.5948, 0.6027, 0.5725, 0.5822, 0.5427, 0.6755, 0.5896, 0.5705, 0.5506, 0.5476, 0.5727, 0.5669, 0.571, 0.5067, 0.4648, 0.7207, 0.4973, 0.4724, 0.4553, 0.4842, 0.4296, 0.4841, 0.4953, 0.4855, 0.5869, 0.4474, 0.4447, 0.4105, 0.4273, 0.4709, 0.4393, 0.4252, 0.4545, 0.4388, 0.4379, 0.3957, 0.3996, 0.4932, 0.4574, 0.4418, 0.431, 0.3965, 0.4604, 0.417, 0.4175, 0.4228, 0.4054, 0.473, 0.4141, 0.4364, 0.4251, 0.5781, 0.5593, 0.4059, 0.4062, 0.4963, 0.4484, 0.3951, 0.4571, 0.816, 0.4208, 0.3779, 0.4458, 0.6286, 0.3843, 0.605, 0.4562, 0.4779, 0.3972, 0.4218, 0.3987, 0.4179, 0.3914, 0.3669, 0.3525, 0.3918, 0.4048, 0.4272, 0.3941, 0.4433, 0.4607, 0.4182, 0.4002, 0.4526, 0.4356, 0.4032, 0.3845, 0.349, 0.5614, 0.4086]
Val Accuracies: [60.5, 63.5, 64.0, 66.67, 66.33, 65.33, 66.83, 66.33, 69.33, 66.33, 69.33, 68.0, 70.67, 72.67, 70.67, 66.5, 72.33, 69.5, 73.5, 73.17, 70.0, 75.67, 72.83, 76.67, 76.67, 67.17, 77.67, 79.0, 80.5, 78.83, 78.33, 78.33, 77.5, 78.5, 75.33, 80.33, 79.5, 81.0, 82.0, 79.67, 80.83, 82.17, 81.5, 81.17, 82.83, 82.5, 83.17, 79.33, 80.67, 80.83, 81.0, 82.5, 80.83, 83.17, 83.33, 83.17, 82.5, 81.83, 83.33, 81.17, 83.5, 79.83, 77.67, 85.0, 83.5, 83.83, 82.67, 83.83, 83.83, 71.33, 83.67, 85.67, 83.17, 78.17, 85.33, 78.67, 82.0, 82.0, 85.83, 85.0, 84.67, 84.17, 84.33, 85.83, 85.83, 86.33, 85.0, 85.33, 86.17, 85.17, 83.17, 85.67, 85.17, 84.83, 83.83, 87.17, 86.0, 88.67, 82.5, 86.67]
