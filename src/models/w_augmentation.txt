==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ConvolutionalNetwork                     [64, 2]                   --
├─Sequential: 1-1                        [64, 256, 14, 14]         387,520
│    └─Conv2d: 2-1                       [64, 32, 224, 224]        896
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-2                         [64, 32, 224, 224]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-3                    [64, 32, 112, 112]        --
│    └─Conv2d: 2-4                       [64, 64, 112, 112]        18,496
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-5                         [64, 64, 112, 112]        --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-6                    [64, 64, 56, 56]          --
│    └─Conv2d: 2-7                       [64, 128, 56, 56]         73,856
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-8                         [64, 128, 56, 56]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-9                    [64, 128, 28, 28]         --
│    └─Conv2d: 2-10                      [64, 256, 28, 28]         295,168
├─Sequential: 1-8                        --                        (recursive)
│    └─ReLU: 2-11                        [64, 256, 28, 28]         --
├─Sequential: 1-9                        --                        (recursive)
│    └─MaxPool2d: 2-12                   [64, 256, 14, 14]         --
├─Sequential: 1-10                       [64, 2]                   --
│    └─Linear: 2-13                      [64, 256]                 12,845,312
│    └─ReLU: 2-14                        [64, 256]                 --
│    └─Linear: 2-15                      [64, 128]                 32,896
│    └─ReLU: 2-16                        [64, 128]                 --
│    └─Linear: 2-17                      [64, 2]                   258
==========================================================================================
Total params: 13,654,402
Trainable params: 13,654,402
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 48.18
==========================================================================================
Input size (MB): 38.54
Forward/backward pass size (MB): 1541.60
Params size (MB): 53.07
Estimated Total Size (MB): 1633.21
==========================================================================================
Training and Validation Metrics:
Train Losses: [0.6994, 0.6895, 0.6801, 0.6598, 0.6371, 0.6208, 0.6096, 0.5936, 0.5776, 0.5514, 0.5418, 0.5302, 0.5586, 0.5514, 0.5221, 0.4971, 0.5, 0.4822, 0.4796, 0.4964, 0.4484, 0.465, 0.4698, 0.4604, 0.4516, 0.4324, 0.4048, 0.4169, 0.4174, 0.3744, 0.3946, 0.3896, 0.357, 0.372, 0.3777, 0.359, 0.3132, 0.3517, 0.3332, 0.3167, 0.3366, 0.3023, 0.3226, 0.341, 0.2803, 0.2632, 0.269, 0.28, 0.3054, 0.254, 0.2448, 0.2511, 0.2566, 0.2481, 0.2428, 0.2408, 0.2381, 0.2443, 0.2241, 0.204, 0.1963, 0.1884, 0.1929, 0.2146, 0.1977, 0.2258, 0.2171, 0.1954, 0.1857, 0.192, 0.213, 0.1979, 0.1767, 0.1656, 0.1819, 0.164, 0.1723, 0.1559, 0.1657, 0.1373, 0.1428, 0.1931, 0.1341, 0.1632, 0.1598, 0.1448, 0.1676, 0.1412, 0.1353, 0.1245, 0.1351, 0.1204, 0.1281, 0.1511, 0.1466, 0.1164, 0.1358, 0.1526, 0.1201, 0.1278, 0.1037, 0.1052, 0.1343, 0.1016, 0.1025, 0.1005, 0.1053, 0.0956, 0.099, 0.1009, 0.1411, 0.1319, 0.1309, 0.1069, 0.091, 0.1115, 0.1119, 0.1028, 0.0835, 0.0785]
Train Accuracies: [51.7, 53.75, 54.3, 59.65, 64.4, 65.1, 66.5, 67.8, 69.35, 70.85, 71.05, 72.05, 70.55, 71.9, 73.55, 76.05, 76.45, 77.2, 77.05, 76.4, 78.9, 79.0, 77.7, 78.5, 78.15, 79.65, 80.9, 80.4, 79.1, 83.4, 82.45, 82.05, 83.8, 83.8, 83.05, 84.55, 85.8, 83.7, 84.8, 85.8, 84.85, 86.95, 86.0, 85.15, 87.95, 88.6, 88.9, 87.25, 85.7, 88.55, 89.65, 89.6, 89.35, 89.65, 90.4, 89.8, 89.55, 89.1, 90.75, 91.3, 91.95, 91.75, 92.9, 91.05, 92.1, 90.85, 90.5, 92.65, 92.35, 92.65, 91.45, 91.45, 92.95, 94.2, 92.65, 93.85, 92.85, 93.6, 92.95, 94.05, 94.15, 92.45, 94.8, 93.45, 93.85, 94.25, 93.4, 94.55, 94.55, 95.55, 95.0, 95.25, 94.3, 93.95, 94.25, 95.45, 94.6, 93.85, 95.6, 94.75, 95.5, 96.05, 94.55, 95.8, 95.9, 96.0, 95.8, 96.05, 96.3, 96.6, 94.25, 94.55, 94.85, 95.8, 96.2, 95.6, 95.45, 96.25, 96.95, 97.15]
Val Losses: [0.6878, 0.6895, 0.6847, 0.6549, 0.6706, 0.6582, 0.6502, 0.6547, 0.5995, 0.6134, 0.5918, 0.5703, 0.5582, 0.545, 0.5334, 0.5384, 0.5475, 0.5633, 0.5226, 0.5302, 0.6042, 0.5727, 0.5292, 0.4854, 0.527, 0.4821, 0.4799, 0.5001, 0.4819, 0.5007, 0.5338, 0.4811, 0.4761, 0.5233, 0.4648, 0.4369, 0.5858, 0.4601, 0.4874, 0.4798, 0.4495, 0.4302, 0.5216, 0.4522, 0.5553, 0.4526, 0.4936, 0.7044, 0.4693, 0.4721, 0.504, 0.4375, 0.5014, 0.4713, 0.5083, 0.477, 0.4902, 0.4495, 0.5438, 0.4785, 0.4777, 0.4696, 0.4613, 0.4857, 0.4766, 0.4648, 0.5159, 0.5347, 0.5925, 0.5608, 0.5002, 0.4596, 0.5268, 0.4926, 0.4421, 0.5294, 0.578, 0.5791, 0.5074, 0.658, 0.6294, 0.5093, 0.5239, 0.5531, 0.4482, 0.6787, 0.4874, 0.5527, 0.5746, 0.5443, 0.5426, 0.5516, 0.6152, 0.5863, 0.5165, 0.5992, 0.5839, 0.5531, 0.5915, 0.541, 0.6229, 0.619, 0.487, 0.6222, 0.5933, 0.532, 0.5832, 0.5449, 0.6869, 0.6611, 0.524, 0.7344, 0.4805, 0.5167, 0.6112, 0.487, 0.5688, 0.5792, 0.5764, 0.7381]
Val Accuracies: [60.17, 50.33, 55.33, 60.83, 61.67, 62.33, 65.0, 66.0, 68.83, 68.83, 71.0, 71.17, 71.33, 73.17, 72.33, 75.0, 72.83, 72.33, 77.83, 74.0, 74.0, 70.17, 75.83, 77.67, 76.0, 77.17, 79.83, 80.5, 80.0, 80.67, 75.83, 79.0, 80.67, 81.0, 78.0, 82.83, 78.67, 81.67, 82.33, 80.83, 80.5, 83.5, 77.67, 81.0, 80.5, 83.83, 83.0, 80.5, 80.83, 83.67, 83.17, 84.83, 82.17, 85.67, 84.83, 84.83, 84.33, 85.17, 83.83, 83.17, 84.67, 85.67, 82.33, 83.5, 84.67, 82.67, 82.0, 85.33, 83.33, 85.0, 84.33, 84.0, 83.0, 84.83, 85.17, 83.67, 85.17, 82.83, 83.5, 84.17, 83.67, 86.67, 85.33, 85.0, 85.67, 86.33, 85.17, 86.17, 85.67, 85.67, 84.17, 86.0, 84.17, 86.0, 85.17, 86.0, 85.67, 86.67, 86.67, 86.5, 85.83, 84.67, 87.17, 85.67, 86.33, 86.5, 86.67, 87.33, 86.33, 85.5, 85.0, 84.67, 86.0, 86.5, 86.17, 87.0, 85.17, 86.5, 88.5, 88.83]
